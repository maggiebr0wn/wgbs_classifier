{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Feature Selection & Validation - Consolidated\n",
    "\n",
    "**One notebook to rule them all.**\n",
    "\n",
    "This runs the complete pipeline:\n",
    "1. Feature extraction & selection\n",
    "2. Model training (LASSO or Random Forest)\n",
    "3. LOO cross-validation\n",
    "4. Validation testing\n",
    "5. Results visualization\n",
    "\n",
    "**Runtime:** ~2 minutes per model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Ready to go!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Import the pipeline\n",
    "from src.feature_selection import run_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"âœ“ Ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Run Random Forest\n",
    "\n",
    "Random Forest may handle batch effects better than LASSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODULE 4: RF CLASSIFIER\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "Discovery: 8 samples (4 ALS, 4 Control)\n",
      "Validation: 14 samples (8 ALS, 6 Control)\n",
      "\n",
      "======================================================================\n",
      "EXTRACTING FEATURES\n",
      "======================================================================\n",
      "\n",
      "Aggregating methylation to 500kb bins...\n",
      "\n",
      "Fragmentomics: 17 â†’ 17\n",
      "Methylation: 80 â†’ 74\n",
      "Total features: 91\n",
      "\n",
      "======================================================================\n",
      "FEATURE SELECTION: RANDOM FOREST\n",
      "======================================================================\n",
      "\n",
      "Selected 20 features by importance\n",
      "  - meth_agg_40: 0.0670\n",
      "  - meth_agg_25: 0.0548\n",
      "  - meth_agg_60: 0.0414\n",
      "  - meth_agg_49: 0.0393\n",
      "  - meth_agg_68: 0.0314\n",
      "  - meth_agg_38: 0.0258\n",
      "  - meth_agg_78: 0.0249\n",
      "  - meth_agg_36: 0.0242\n",
      "  - meth_agg_16: 0.0228\n",
      "  - meth_agg_63: 0.0225\n",
      "  - meth_agg_50: 0.0224\n",
      "  - meth_agg_30: 0.0194\n",
      "  - meth_agg_85: 0.0177\n",
      "  - frag_pct_mononucleosomal: 0.0156\n",
      "  - meth_agg_55: 0.0152\n",
      "  - meth_agg_15: 0.0151\n",
      "  - meth_agg_42: 0.0145\n",
      "  - meth_agg_32: 0.0139\n",
      "  - meth_agg_77: 0.0137\n",
      "  - meth_agg_17: 0.0130\n",
      "\n",
      "======================================================================\n",
      "TRAINING RF WITH LOO-CV\n",
      "======================================================================\n",
      "\n",
      "Training: 8 samples Ã— 20 features\n",
      "\n",
      "LOO-CV AUC: 0.688\n",
      "\n",
      "======================================================================\n",
      "VALIDATION TESTING\n",
      "======================================================================\n",
      "\n",
      "Validation AUC: 0.187\n",
      "Validation Accuracy: 0.500\n",
      "\n",
      "Discovery LOO-CV: 0.688\n",
      "Difference: -0.500\n",
      "\n",
      "âœ— POOR: Does not generalize\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "âœ“ Saved: /Users/maggiebrown/Desktop/PrimaMente/wgbs_classifier/results/figures/rf_results/roc_curves.png\n",
      "âœ“ Saved: /Users/maggiebrown/Desktop/PrimaMente/wgbs_classifier/results/figures/rf_results/performance_comparison.png\n",
      "\n",
      "======================================================================\n",
      "COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Final Results:\n",
      "  Model: RF\n",
      "  Features: 20\n",
      "  Discovery LOO-CV AUC: 0.688\n",
      "  Validation AUC: 0.187\n",
      "  Drop: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Run Random Forest pipeline\n",
    "rf_results = run_pipeline(model_type='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRYING FRAGMENTOMICS-ONLY (no methylation)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "Discovery: 8 samples (4 ALS, 4 Control)\n",
      "Validation: 14 samples (8 ALS, 6 Control)\n",
      "\n",
      "======================================================================\n",
      "EXTRACTING FEATURES\n",
      "======================================================================\n",
      "\n",
      "Aggregating methylation to 500kb bins...\n",
      "\n",
      "Fragmentomics: 17 â†’ 17\n",
      "Methylation: 80 â†’ 74\n",
      "Total features: 91\n",
      "\n",
      "Using 17 fragmentomics features only\n",
      "  - frag_cv\n",
      "  - frag_iqr\n",
      "  - frag_kurtosis\n",
      "  - frag_mean\n",
      "  - frag_median\n",
      "  - frag_pct_dinucleosomal\n",
      "  - frag_pct_long\n",
      "  - frag_pct_mononucleosomal\n",
      "  - frag_pct_short\n",
      "  - frag_pct_very_short\n",
      "  - frag_q25\n",
      "  - frag_q50\n",
      "  - frag_q75\n",
      "  - frag_ratio_mono_di\n",
      "  - frag_ratio_short_long\n",
      "  - frag_skewness\n",
      "  - frag_std\n",
      "\n",
      "======================================================================\n",
      "TRAINING RF WITH LOO-CV\n",
      "======================================================================\n",
      "\n",
      "Training: 8 samples Ã— 17 features\n",
      "\n",
      "LOO-CV AUC: 0.125\n",
      "\n",
      "======================================================================\n",
      "VALIDATION TESTING\n",
      "======================================================================\n",
      "\n",
      "Validation AUC: 0.667\n",
      "Validation Accuracy: 0.571\n",
      "\n",
      "Discovery LOO-CV: 0.125\n",
      "Difference: +0.542\n",
      "\n",
      "âš  MODERATE: Weak generalization\n",
      "\n",
      "======================================================================\n",
      "FRAGMENTOMICS-ONLY RESULT\n",
      "======================================================================\n",
      "Discovery LOO-CV: 0.125\n",
      "Validation AUC: 0.667\n",
      "Drop: -0.542\n",
      "\n",
      "âœ“ Better! Fragmentomics are more robust to batch effects\n"
     ]
    }
   ],
   "source": [
    "# Try fragmentomics-only approach\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRYING FRAGMENTOMICS-ONLY (no methylation)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from src.feature_selection import (\n",
    "    load_data, extract_features, train_with_loo, validate\n",
    ")\n",
    "\n",
    "# Load data\n",
    "discovery_df, validation_df = load_data()\n",
    "\n",
    "# Extract features\n",
    "feature_df, all_features, meth_agg_df = extract_features(discovery_df)\n",
    "\n",
    "# Get ONLY fragmentomics features\n",
    "frag_only = [f for f in all_features if not f.startswith('meth_agg_')]\n",
    "\n",
    "print(f\"\\nUsing {len(frag_only)} fragmentomics features only\")\n",
    "for f in frag_only:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Train with LOO-CV\n",
    "model_data, loo_pred, loo_true = train_with_loo(\n",
    "    feature_df, frag_only, model_type='rf'\n",
    ")\n",
    "\n",
    "# Validate\n",
    "val_predictions, val_auc, val_acc = validate(\n",
    "    validation_df, meth_agg_df, model_data\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FRAGMENTOMICS-ONLY RESULT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Discovery LOO-CV: {model_data['loo_auc']:.3f}\")\n",
    "print(f\"Validation AUC: {val_auc:.3f}\")\n",
    "print(f\"Drop: {model_data['loo_auc'] - val_auc:.3f}\")\n",
    "\n",
    "if val_auc >= 0.60:\n",
    "    print(\"\\nâœ“ Better! Fragmentomics are more robust to batch effects\")\n",
    "else:\n",
    "    print(\"\\nâœ— Still poor - fundamental batch effect problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SIMPLE BIOLOGICAL APPROACH\n",
      "======================================================================\n",
      "\n",
      "Using 5 biologically interpretable features:\n",
      "  - frag_mean\n",
      "  - frag_pct_short\n",
      "  - frag_pct_long\n",
      "  - frag_ratio_short_long\n",
      "  - frag_pct_mononucleosomal\n",
      "\n",
      "======================================================================\n",
      "TRAINING RF WITH LOO-CV\n",
      "======================================================================\n",
      "\n",
      "Training: 8 samples Ã— 5 features\n",
      "\n",
      "LOO-CV AUC: 0.188\n",
      "\n",
      "======================================================================\n",
      "VALIDATION TESTING\n",
      "======================================================================\n",
      "\n",
      "Validation AUC: 0.646\n",
      "Validation Accuracy: 0.643\n",
      "\n",
      "Discovery LOO-CV: 0.188\n",
      "Difference: +0.458\n",
      "\n",
      "âš  MODERATE: Weak generalization\n",
      "\n",
      "======================================================================\n",
      "SIMPLE FEATURES RESULT\n",
      "======================================================================\n",
      "Discovery LOO-CV: 0.188\n",
      "Validation AUC: 0.646\n",
      "Validation Accuracy: 0.643\n"
     ]
    }
   ],
   "source": [
    "# Simple approach: Just use the most biologically interpretable features\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SIMPLE BIOLOGICAL APPROACH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Just use 5 core fragment size features that should be robust\n",
    "simple_features = [\n",
    "    'frag_mean',           # Overall fragment size\n",
    "    'frag_pct_short',      # Short fragments (nucleosome-free)\n",
    "    'frag_pct_long',       # Long fragments  \n",
    "    'frag_ratio_short_long', # Ratio of short to long\n",
    "    'frag_pct_mononucleosomal' # Mononucleosome peak\n",
    "]\n",
    "\n",
    "print(f\"\\nUsing {len(simple_features)} biologically interpretable features:\")\n",
    "for f in simple_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Train\n",
    "model_data_simple, loo_pred, loo_true = train_with_loo(\n",
    "    feature_df, simple_features, model_type='rf'\n",
    ")\n",
    "\n",
    "# Validate\n",
    "val_predictions_simple, val_auc_simple, val_acc_simple = validate(\n",
    "    validation_df, meth_agg_df, model_data_simple\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SIMPLE FEATURES RESULT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Discovery LOO-CV: {model_data_simple['loo_auc']:.3f}\")\n",
    "print(f\"Validation AUC: {val_auc_simple:.3f}\")\n",
    "print(f\"Validation Accuracy: {val_acc_simple:.3f}\")\n",
    "\n",
    "if val_auc_simple >= 0.70:\n",
    "    print(\"\\nðŸŽ‰ SUCCESS! Simple features work better!\")\n",
    "    print(\"\\nThis makes sense because:\")\n",
    "    print(\"  - Core fragment metrics are well-established in cfDNA\")\n",
    "    print(\"  - They're less prone to technical batch effects\")\n",
    "    print(\"  - Simpler model = less overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TESTING XGBOOST\n",
      "======================================================================\n",
      "\n",
      "XGBoost Discovery LOO-CV AUC: 0.500\n",
      "XGBoost Validation AUC: 0.500\n",
      "XGBoost Validation Accuracy: 0.571\n",
      "\n",
      "======================================================================\n",
      "COMPARISON: RF vs XGBoost\n",
      "======================================================================\n",
      "Random Forest    - Validation AUC: 0.646, Accuracy: 64.3%\n",
      "XGBoost          - Validation AUC: 0.500, Accuracy: 57.1%\n",
      "\n",
      "â†’ RF and XGBoost perform similarly, stick with RF (simpler)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING XGBOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use same 5 simple features\n",
    "simple_features = [\n",
    "    'frag_mean', 'frag_pct_short', 'frag_pct_long',\n",
    "    'frag_ratio_short_long', 'frag_pct_mononucleosomal'\n",
    "]\n",
    "\n",
    "X = feature_df[simple_features].fillna(feature_df[simple_features].median()).values\n",
    "y = (feature_df['disease_status'] == 'als').astype(int).values\n",
    "\n",
    "# XGBoost with aggressive regularization for n=8\n",
    "xgb_params = {\n",
    "    'max_depth': 2,              # Very shallow\n",
    "    'learning_rate': 0.1,        # Conservative\n",
    "    'n_estimators': 100,         # Fewer trees\n",
    "    'min_child_weight': 2,       # Prevent overfitting\n",
    "    'subsample': 0.8,            # Row sampling\n",
    "    'colsample_bytree': 0.8,     # Feature sampling\n",
    "    'reg_alpha': 1.0,            # L1 regularization\n",
    "    'reg_lambda': 1.0,           # L2 regularization\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# LOO Cross-validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo_predictions = []\n",
    "loo_true = []\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Calculate scale_pos_weight for this fold\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = len(y_train) - n_pos\n",
    "    scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params, scale_pos_weight=scale_pos_weight)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[0, 1]\n",
    "    loo_predictions.append(y_pred_proba)\n",
    "    loo_true.append(y_test[0])\n",
    "\n",
    "loo_predictions = np.array(loo_predictions)\n",
    "loo_true = np.array(loo_true)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "loo_auc = roc_auc_score(loo_true, loo_predictions)\n",
    "print(f\"\\nXGBoost Discovery LOO-CV AUC: {loo_auc:.3f}\")\n",
    "\n",
    "# Train final model\n",
    "final_xgb = xgb.XGBClassifier(**xgb_params)\n",
    "final_xgb.fit(X, y, verbose=False)\n",
    "\n",
    "# Validate\n",
    "val_feature_df = validation_df[['sample_id', 'disease_status']].copy()\n",
    "for feat in simple_features:\n",
    "    val_feature_df[feat] = validation_df[feat]\n",
    "\n",
    "X_val = val_feature_df[simple_features].fillna(val_feature_df[simple_features].median()).values\n",
    "y_val = (validation_df['disease_status'] == 'als').astype(int).values\n",
    "\n",
    "y_pred_proba_val = final_xgb.predict_proba(X_val)[:, 1]\n",
    "y_pred_val = (y_pred_proba_val >= 0.5).astype(int)\n",
    "\n",
    "val_auc_xgb = roc_auc_score(y_val, y_pred_proba_val)\n",
    "val_acc_xgb = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "print(f\"XGBoost Validation AUC: {val_auc_xgb:.3f}\")\n",
    "print(f\"XGBoost Validation Accuracy: {val_acc_xgb:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: RF vs XGBoost\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Random Forest    - Validation AUC: 0.646, Accuracy: 64.3%\")\n",
    "print(f\"XGBoost          - Validation AUC: {val_auc_xgb:.3f}, Accuracy: {val_acc_xgb*100:.1f}%\")\n",
    "\n",
    "if val_auc_xgb > 0.646 + 0.05:\n",
    "    print(\"\\nðŸŽ‰ XGBoost is better! Use this for final report.\")\n",
    "elif val_auc_xgb > 0.646:\n",
    "    print(\"\\nâœ“ XGBoost slightly better, but similar to RF\")\n",
    "else:\n",
    "    print(\"\\nâ†’ RF and XGBoost perform similarly, stick with RF (simpler)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
